{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3867f65d",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad1e2870",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "661061d9",
   "metadata": {},
   "source": [
    "# Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "834845b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load from pkl\n",
    "xall, yall, harai = joblib.load(\"./data.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c3bb74c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raceid</th>\n",
       "      <th>horseid</th>\n",
       "      <th>racedate</th>\n",
       "      <th>futan</th>\n",
       "      <th>umaban</th>\n",
       "      <th>wakuban</th>\n",
       "      <th>blinker</th>\n",
       "      <th>age</th>\n",
       "      <th>bataijyu</th>\n",
       "      <th>zogen</th>\n",
       "      <th>...</th>\n",
       "      <th>grade_5</th>\n",
       "      <th>wintime_5</th>\n",
       "      <th>lap_s3_5</th>\n",
       "      <th>lap_s4_5</th>\n",
       "      <th>lap_l3_5</th>\n",
       "      <th>lap_l4_5</th>\n",
       "      <th>f</th>\n",
       "      <th>ff</th>\n",
       "      <th>m</th>\n",
       "      <th>mf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020010506010101</td>\n",
       "      <td>2017103291</td>\n",
       "      <td>20200105</td>\n",
       "      <td>54.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>432.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.120002e+09</td>\n",
       "      <td>1.120002e+09</td>\n",
       "      <td>1.220057e+09</td>\n",
       "      <td>1.120002e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020010506010101</td>\n",
       "      <td>2017101861</td>\n",
       "      <td>20200105</td>\n",
       "      <td>54.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>424.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.120002e+09</td>\n",
       "      <td>1.140004e+09</td>\n",
       "      <td>1.220063e+09</td>\n",
       "      <td>1.120002e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020010506010101</td>\n",
       "      <td>2017103186</td>\n",
       "      <td>20200105</td>\n",
       "      <td>54.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>458.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.120002e+09</td>\n",
       "      <td>1.120002e+09</td>\n",
       "      <td>1.220061e+09</td>\n",
       "      <td>1.140006e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020010506010101</td>\n",
       "      <td>2017102095</td>\n",
       "      <td>20200105</td>\n",
       "      <td>53.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>464.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.120002e+09</td>\n",
       "      <td>1.120002e+09</td>\n",
       "      <td>1.220062e+09</td>\n",
       "      <td>1.120002e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020010506010101</td>\n",
       "      <td>2017103287</td>\n",
       "      <td>20200105</td>\n",
       "      <td>52.0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>460.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.120002e+09</td>\n",
       "      <td>1.140006e+09</td>\n",
       "      <td>1.220062e+09</td>\n",
       "      <td>1.140005e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143318</th>\n",
       "      <td>2022122809060912</td>\n",
       "      <td>2018105223</td>\n",
       "      <td>20221228</td>\n",
       "      <td>53.0</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>452.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>E</td>\n",
       "      <td>69.4</td>\n",
       "      <td>33.6</td>\n",
       "      <td>45.3</td>\n",
       "      <td>35.8</td>\n",
       "      <td>46.9</td>\n",
       "      <td>1.140007e+09</td>\n",
       "      <td>1.140005e+09</td>\n",
       "      <td>1.220065e+09</td>\n",
       "      <td>1.140006e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143319</th>\n",
       "      <td>2022122809060912</td>\n",
       "      <td>2017106137</td>\n",
       "      <td>20221228</td>\n",
       "      <td>56.0</td>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>492.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>E</td>\n",
       "      <td>67.3</td>\n",
       "      <td>32.8</td>\n",
       "      <td>44.1</td>\n",
       "      <td>34.5</td>\n",
       "      <td>45.4</td>\n",
       "      <td>1.120002e+09</td>\n",
       "      <td>1.140004e+09</td>\n",
       "      <td>1.220050e+09</td>\n",
       "      <td>1.120002e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143320</th>\n",
       "      <td>2022122809060912</td>\n",
       "      <td>2017100461</td>\n",
       "      <td>20221228</td>\n",
       "      <td>56.0</td>\n",
       "      <td>14</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>504.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>E</td>\n",
       "      <td>80.4</td>\n",
       "      <td>35.6</td>\n",
       "      <td>47.1</td>\n",
       "      <td>33.3</td>\n",
       "      <td>44.8</td>\n",
       "      <td>1.120002e+09</td>\n",
       "      <td>1.140004e+09</td>\n",
       "      <td>1.220055e+09</td>\n",
       "      <td>1.120002e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143321</th>\n",
       "      <td>2022122809060912</td>\n",
       "      <td>2018106389</td>\n",
       "      <td>20221228</td>\n",
       "      <td>52.0</td>\n",
       "      <td>15</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>434.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>E</td>\n",
       "      <td>68.4</td>\n",
       "      <td>33.7</td>\n",
       "      <td>45.0</td>\n",
       "      <td>34.7</td>\n",
       "      <td>45.7</td>\n",
       "      <td>1.120002e+09</td>\n",
       "      <td>1.140005e+09</td>\n",
       "      <td>1.220063e+09</td>\n",
       "      <td>1.120002e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143322</th>\n",
       "      <td>2022122809060912</td>\n",
       "      <td>2019106184</td>\n",
       "      <td>20221228</td>\n",
       "      <td>53.0</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>456.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>66.8</td>\n",
       "      <td>32.4</td>\n",
       "      <td>43.5</td>\n",
       "      <td>34.4</td>\n",
       "      <td>45.0</td>\n",
       "      <td>1.120002e+09</td>\n",
       "      <td>1.120002e+09</td>\n",
       "      <td>1.220066e+09</td>\n",
       "      <td>1.140006e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>143323 rows × 224 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  raceid     horseid  racedate  futan  umaban  wakuban  \\\n",
       "0       2020010506010101  2017103291  20200105   54.0       1        1   \n",
       "1       2020010506010101  2017101861  20200105   54.0       2        1   \n",
       "2       2020010506010101  2017103186  20200105   54.0       3        2   \n",
       "3       2020010506010101  2017102095  20200105   53.0       4        2   \n",
       "4       2020010506010101  2017103287  20200105   52.0       5        3   \n",
       "...                  ...         ...       ...    ...     ...      ...   \n",
       "143318  2022122809060912  2018105223  20221228   53.0      12        6   \n",
       "143319  2022122809060912  2017106137  20221228   56.0      13        7   \n",
       "143320  2022122809060912  2017100461  20221228   56.0      14        7   \n",
       "143321  2022122809060912  2018106389  20221228   52.0      15        8   \n",
       "143322  2022122809060912  2019106184  20221228   53.0      16        8   \n",
       "\n",
       "        blinker  age  bataijyu  zogen  ...  grade_5  wintime_5  lap_s3_5  \\\n",
       "0             0  3.0     432.0    4.0  ...     None        NaN       NaN   \n",
       "1             0  3.0     424.0   -4.0  ...     None        NaN       NaN   \n",
       "2             0  3.0     458.0    0.0  ...     None        NaN       NaN   \n",
       "3             0  3.0     464.0   10.0  ...     None        NaN       NaN   \n",
       "4             1  3.0     460.0   -2.0  ...     None        NaN       NaN   \n",
       "...         ...  ...       ...    ...  ...      ...        ...       ...   \n",
       "143318        0  4.0     452.0    0.0  ...        E       69.4      33.6   \n",
       "143319        0  5.0     492.0    6.0  ...        E       67.3      32.8   \n",
       "143320        0  5.0     504.0    4.0  ...        E       80.4      35.6   \n",
       "143321        0  4.0     434.0    2.0  ...        E       68.4      33.7   \n",
       "143322        0  3.0     456.0   -2.0  ...                66.8      32.4   \n",
       "\n",
       "        lap_s4_5 lap_l3_5 lap_l4_5             f            ff             m  \\\n",
       "0            NaN      NaN      NaN  1.120002e+09  1.120002e+09  1.220057e+09   \n",
       "1            NaN      NaN      NaN  1.120002e+09  1.140004e+09  1.220063e+09   \n",
       "2            NaN      NaN      NaN  1.120002e+09  1.120002e+09  1.220061e+09   \n",
       "3            NaN      NaN      NaN  1.120002e+09  1.120002e+09  1.220062e+09   \n",
       "4            NaN      NaN      NaN  1.120002e+09  1.140006e+09  1.220062e+09   \n",
       "...          ...      ...      ...           ...           ...           ...   \n",
       "143318      45.3     35.8     46.9  1.140007e+09  1.140005e+09  1.220065e+09   \n",
       "143319      44.1     34.5     45.4  1.120002e+09  1.140004e+09  1.220050e+09   \n",
       "143320      47.1     33.3     44.8  1.120002e+09  1.140004e+09  1.220055e+09   \n",
       "143321      45.0     34.7     45.7  1.120002e+09  1.140005e+09  1.220063e+09   \n",
       "143322      43.5     34.4     45.0  1.120002e+09  1.120002e+09  1.220066e+09   \n",
       "\n",
       "                  mf  \n",
       "0       1.120002e+09  \n",
       "1       1.120002e+09  \n",
       "2       1.140006e+09  \n",
       "3       1.120002e+09  \n",
       "4       1.140005e+09  \n",
       "...              ...  \n",
       "143318  1.140006e+09  \n",
       "143319  1.120002e+09  \n",
       "143320  1.120002e+09  \n",
       "143321  1.120002e+09  \n",
       "143322  1.140006e+09  \n",
       "\n",
       "[143323 rows x 224 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input features\n",
    "xall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "46ff955f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          2\n",
       "1         12\n",
       "2          3\n",
       "3         11\n",
       "4          8\n",
       "          ..\n",
       "143318    12\n",
       "143319    16\n",
       "143320    11\n",
       "143321     7\n",
       "143322     8\n",
       "Name: jyuni, Length: 143323, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Output feature: finishing position (0: race not finished)\n",
    "yall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9fd9b99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RaceID</th>\n",
       "      <th>TorokuTosu</th>\n",
       "      <th>SyussoTosu</th>\n",
       "      <th>FuseirituFlag</th>\n",
       "      <th>TokubaraiFlag</th>\n",
       "      <th>HenkanFlag</th>\n",
       "      <th>HenkanUma</th>\n",
       "      <th>HenkanWaku</th>\n",
       "      <th>HenkanDoWaku</th>\n",
       "      <th>PayTansyo</th>\n",
       "      <th>...</th>\n",
       "      <th>PayReserved1</th>\n",
       "      <th>PayUmatan</th>\n",
       "      <th>PaySanrenpuku</th>\n",
       "      <th>PaySanrentan</th>\n",
       "      <th>Year</th>\n",
       "      <th>MonthDay</th>\n",
       "      <th>JyoCD</th>\n",
       "      <th>Kaiji</th>\n",
       "      <th>Nichiji</th>\n",
       "      <th>RaceNum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020010606010203</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[{'Umaban': '09', 'Pay': '000000200', 'Ninki':...</td>\n",
       "      <td>...</td>\n",
       "      <td>[{'Kumi': '    ', 'Pay': '         ', 'Ninki':...</td>\n",
       "      <td>[{'Kumi': '0913', 'Pay': '000000510', 'Ninki':...</td>\n",
       "      <td>[{'Kumi': '080913', 'Pay': '000001270', 'Ninki...</td>\n",
       "      <td>[{'Kumi': '091308', 'Pay': '000003840', 'Ninki...</td>\n",
       "      <td>2020</td>\n",
       "      <td>0106</td>\n",
       "      <td>06</td>\n",
       "      <td>01</td>\n",
       "      <td>02</td>\n",
       "      <td>03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022010507010112</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[{'Umaban': '13', 'Pay': '000001530', 'Ninki':...</td>\n",
       "      <td>...</td>\n",
       "      <td>[{'Kumi': '    ', 'Pay': '         ', 'Ninki':...</td>\n",
       "      <td>[{'Kumi': '1315', 'Pay': '000004070', 'Ninki':...</td>\n",
       "      <td>[{'Kumi': '061315', 'Pay': '000002720', 'Ninki...</td>\n",
       "      <td>[{'Kumi': '131506', 'Pay': '000026590', 'Ninki...</td>\n",
       "      <td>2022</td>\n",
       "      <td>0105</td>\n",
       "      <td>07</td>\n",
       "      <td>01</td>\n",
       "      <td>01</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020010506010101</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[{'Umaban': '07', 'Pay': '000000360', 'Ninki':...</td>\n",
       "      <td>...</td>\n",
       "      <td>[{'Kumi': '    ', 'Pay': '         ', 'Ninki':...</td>\n",
       "      <td>[{'Kumi': '0701', 'Pay': '000003650', 'Ninki':...</td>\n",
       "      <td>[{'Kumi': '010307', 'Pay': '000098210', 'Ninki...</td>\n",
       "      <td>[{'Kumi': '070103', 'Pay': '000280650', 'Ninki...</td>\n",
       "      <td>2020</td>\n",
       "      <td>0105</td>\n",
       "      <td>06</td>\n",
       "      <td>01</td>\n",
       "      <td>01</td>\n",
       "      <td>01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020010606010204</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[{'Umaban': '12', 'Pay': '000000280', 'Ninki':...</td>\n",
       "      <td>...</td>\n",
       "      <td>[{'Kumi': '    ', 'Pay': '         ', 'Ninki':...</td>\n",
       "      <td>[{'Kumi': '1211', 'Pay': '000003040', 'Ninki':...</td>\n",
       "      <td>[{'Kumi': '031112', 'Pay': '000000920', 'Ninki...</td>\n",
       "      <td>[{'Kumi': '121103', 'Pay': '000008340', 'Ninki...</td>\n",
       "      <td>2020</td>\n",
       "      <td>0106</td>\n",
       "      <td>06</td>\n",
       "      <td>01</td>\n",
       "      <td>02</td>\n",
       "      <td>04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020010606010205</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[{'Umaban': '07', 'Pay': '000000380', 'Ninki':...</td>\n",
       "      <td>...</td>\n",
       "      <td>[{'Kumi': '    ', 'Pay': '         ', 'Ninki':...</td>\n",
       "      <td>[{'Kumi': '0716', 'Pay': '000001730', 'Ninki':...</td>\n",
       "      <td>[{'Kumi': '070916', 'Pay': '000002130', 'Ninki...</td>\n",
       "      <td>[{'Kumi': '071609', 'Pay': '000009690', 'Ninki...</td>\n",
       "      <td>2020</td>\n",
       "      <td>0106</td>\n",
       "      <td>06</td>\n",
       "      <td>01</td>\n",
       "      <td>02</td>\n",
       "      <td>05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10363</th>\n",
       "      <td>2022122806050903</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[{'Umaban': '01', 'Pay': '000000600', 'Ninki':...</td>\n",
       "      <td>...</td>\n",
       "      <td>[{'Kumi': '    ', 'Pay': '         ', 'Ninki':...</td>\n",
       "      <td>[{'Kumi': '0107', 'Pay': '000004600', 'Ninki':...</td>\n",
       "      <td>[{'Kumi': '010307', 'Pay': '000023600', 'Ninki...</td>\n",
       "      <td>[{'Kumi': '010703', 'Pay': '000094870', 'Ninki...</td>\n",
       "      <td>2022</td>\n",
       "      <td>1228</td>\n",
       "      <td>06</td>\n",
       "      <td>05</td>\n",
       "      <td>09</td>\n",
       "      <td>03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10364</th>\n",
       "      <td>2022122806050902</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[{'Umaban': '04', 'Pay': '000000750', 'Ninki':...</td>\n",
       "      <td>...</td>\n",
       "      <td>[{'Kumi': '    ', 'Pay': '         ', 'Ninki':...</td>\n",
       "      <td>[{'Kumi': '0406', 'Pay': '000030980', 'Ninki':...</td>\n",
       "      <td>[{'Kumi': '040611', 'Pay': '000013110', 'Ninki...</td>\n",
       "      <td>[{'Kumi': '040611', 'Pay': '000138570', 'Ninki...</td>\n",
       "      <td>2022</td>\n",
       "      <td>1228</td>\n",
       "      <td>06</td>\n",
       "      <td>05</td>\n",
       "      <td>09</td>\n",
       "      <td>02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10365</th>\n",
       "      <td>2022122809060911</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[{'Umaban': '04', 'Pay': '000000520', 'Ninki':...</td>\n",
       "      <td>...</td>\n",
       "      <td>[{'Kumi': '    ', 'Pay': '         ', 'Ninki':...</td>\n",
       "      <td>[{'Kumi': '0410', 'Pay': '000006990', 'Ninki':...</td>\n",
       "      <td>[{'Kumi': '041012', 'Pay': '000004590', 'Ninki...</td>\n",
       "      <td>[{'Kumi': '041012', 'Pay': '000027420', 'Ninki...</td>\n",
       "      <td>2022</td>\n",
       "      <td>1228</td>\n",
       "      <td>09</td>\n",
       "      <td>06</td>\n",
       "      <td>09</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10366</th>\n",
       "      <td>2022122806050911</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[{'Umaban': '11', 'Pay': '000009060', 'Ninki':...</td>\n",
       "      <td>...</td>\n",
       "      <td>[{'Kumi': '    ', 'Pay': '         ', 'Ninki':...</td>\n",
       "      <td>[{'Kumi': '1108', 'Pay': '000175230', 'Ninki':...</td>\n",
       "      <td>[{'Kumi': '081115', 'Pay': '000232970', 'Ninki...</td>\n",
       "      <td>[{'Kumi': '110815', 'Pay': '002466010', 'Ninki...</td>\n",
       "      <td>2022</td>\n",
       "      <td>1228</td>\n",
       "      <td>06</td>\n",
       "      <td>05</td>\n",
       "      <td>09</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10367</th>\n",
       "      <td>2022122809060912</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[{'Umaban': '07', 'Pay': '000000480', 'Ninki':...</td>\n",
       "      <td>...</td>\n",
       "      <td>[{'Kumi': '    ', 'Pay': '         ', 'Ninki':...</td>\n",
       "      <td>[{'Kumi': '0702', 'Pay': '000001890', 'Ninki':...</td>\n",
       "      <td>[{'Kumi': '020407', 'Pay': '000002580', 'Ninki...</td>\n",
       "      <td>[{'Kumi': '070204', 'Pay': '000010260', 'Ninki...</td>\n",
       "      <td>2022</td>\n",
       "      <td>1228</td>\n",
       "      <td>09</td>\n",
       "      <td>06</td>\n",
       "      <td>09</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10368 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 RaceID TorokuTosu SyussoTosu                FuseirituFlag  \\\n",
       "0      2020010606010203         16         16  [0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "1      2022010507010112         16         16  [0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "2      2020010506010101         16         16  [0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "3      2020010606010204         16         16  [0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "4      2020010606010205         16         16  [0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "...                 ...        ...        ...                          ...   \n",
       "10363  2022122806050903         16         16  [0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "10364  2022122806050902         16         16  [0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "10365  2022122809060911         13         13  [0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "10366  2022122806050911         18         18  [0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "10367  2022122809060912         16         16  [0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "\n",
       "                     TokubaraiFlag                   HenkanFlag  \\\n",
       "0      [0, 0, 0, 0, 0, 0, 0, 0, 0]  [0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "1      [0, 0, 0, 0, 0, 0, 0, 0, 0]  [0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "2      [0, 0, 0, 0, 0, 0, 0, 0, 0]  [0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "3      [0, 0, 0, 0, 0, 0, 0, 0, 0]  [0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "4      [0, 0, 0, 0, 0, 0, 0, 0, 0]  [0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "...                            ...                          ...   \n",
       "10363  [0, 0, 0, 0, 0, 0, 0, 0, 0]  [0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "10364  [0, 0, 0, 0, 0, 0, 0, 0, 0]  [0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "10365  [0, 0, 0, 0, 0, 0, 0, 0, 0]  [0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "10366  [0, 0, 0, 0, 0, 0, 0, 0, 0]  [0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "10367  [0, 0, 0, 0, 0, 0, 0, 0, 0]  [0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "\n",
       "                                               HenkanUma  \\\n",
       "0      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "3      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "4      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "...                                                  ...   \n",
       "10363  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "10364  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "10365  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "10366  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "10367  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                     HenkanWaku              HenkanDoWaku  \\\n",
       "0      [0, 0, 0, 0, 0, 0, 0, 0]  [0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "1      [0, 0, 0, 0, 0, 0, 0, 0]  [0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "2      [0, 0, 0, 0, 0, 0, 0, 0]  [0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "3      [0, 0, 0, 0, 0, 0, 0, 0]  [0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "4      [0, 0, 0, 0, 0, 0, 0, 0]  [0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "...                         ...                       ...   \n",
       "10363  [0, 0, 0, 0, 0, 0, 0, 0]  [0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "10364  [0, 0, 0, 0, 0, 0, 0, 0]  [0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "10365  [0, 0, 0, 0, 0, 0, 0, 0]  [0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "10366  [0, 0, 0, 0, 0, 0, 0, 0]  [0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "10367  [0, 0, 0, 0, 0, 0, 0, 0]  [0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "\n",
       "                                               PayTansyo  ...  \\\n",
       "0      [{'Umaban': '09', 'Pay': '000000200', 'Ninki':...  ...   \n",
       "1      [{'Umaban': '13', 'Pay': '000001530', 'Ninki':...  ...   \n",
       "2      [{'Umaban': '07', 'Pay': '000000360', 'Ninki':...  ...   \n",
       "3      [{'Umaban': '12', 'Pay': '000000280', 'Ninki':...  ...   \n",
       "4      [{'Umaban': '07', 'Pay': '000000380', 'Ninki':...  ...   \n",
       "...                                                  ...  ...   \n",
       "10363  [{'Umaban': '01', 'Pay': '000000600', 'Ninki':...  ...   \n",
       "10364  [{'Umaban': '04', 'Pay': '000000750', 'Ninki':...  ...   \n",
       "10365  [{'Umaban': '04', 'Pay': '000000520', 'Ninki':...  ...   \n",
       "10366  [{'Umaban': '11', 'Pay': '000009060', 'Ninki':...  ...   \n",
       "10367  [{'Umaban': '07', 'Pay': '000000480', 'Ninki':...  ...   \n",
       "\n",
       "                                            PayReserved1  \\\n",
       "0      [{'Kumi': '    ', 'Pay': '         ', 'Ninki':...   \n",
       "1      [{'Kumi': '    ', 'Pay': '         ', 'Ninki':...   \n",
       "2      [{'Kumi': '    ', 'Pay': '         ', 'Ninki':...   \n",
       "3      [{'Kumi': '    ', 'Pay': '         ', 'Ninki':...   \n",
       "4      [{'Kumi': '    ', 'Pay': '         ', 'Ninki':...   \n",
       "...                                                  ...   \n",
       "10363  [{'Kumi': '    ', 'Pay': '         ', 'Ninki':...   \n",
       "10364  [{'Kumi': '    ', 'Pay': '         ', 'Ninki':...   \n",
       "10365  [{'Kumi': '    ', 'Pay': '         ', 'Ninki':...   \n",
       "10366  [{'Kumi': '    ', 'Pay': '         ', 'Ninki':...   \n",
       "10367  [{'Kumi': '    ', 'Pay': '         ', 'Ninki':...   \n",
       "\n",
       "                                               PayUmatan  \\\n",
       "0      [{'Kumi': '0913', 'Pay': '000000510', 'Ninki':...   \n",
       "1      [{'Kumi': '1315', 'Pay': '000004070', 'Ninki':...   \n",
       "2      [{'Kumi': '0701', 'Pay': '000003650', 'Ninki':...   \n",
       "3      [{'Kumi': '1211', 'Pay': '000003040', 'Ninki':...   \n",
       "4      [{'Kumi': '0716', 'Pay': '000001730', 'Ninki':...   \n",
       "...                                                  ...   \n",
       "10363  [{'Kumi': '0107', 'Pay': '000004600', 'Ninki':...   \n",
       "10364  [{'Kumi': '0406', 'Pay': '000030980', 'Ninki':...   \n",
       "10365  [{'Kumi': '0410', 'Pay': '000006990', 'Ninki':...   \n",
       "10366  [{'Kumi': '1108', 'Pay': '000175230', 'Ninki':...   \n",
       "10367  [{'Kumi': '0702', 'Pay': '000001890', 'Ninki':...   \n",
       "\n",
       "                                           PaySanrenpuku  \\\n",
       "0      [{'Kumi': '080913', 'Pay': '000001270', 'Ninki...   \n",
       "1      [{'Kumi': '061315', 'Pay': '000002720', 'Ninki...   \n",
       "2      [{'Kumi': '010307', 'Pay': '000098210', 'Ninki...   \n",
       "3      [{'Kumi': '031112', 'Pay': '000000920', 'Ninki...   \n",
       "4      [{'Kumi': '070916', 'Pay': '000002130', 'Ninki...   \n",
       "...                                                  ...   \n",
       "10363  [{'Kumi': '010307', 'Pay': '000023600', 'Ninki...   \n",
       "10364  [{'Kumi': '040611', 'Pay': '000013110', 'Ninki...   \n",
       "10365  [{'Kumi': '041012', 'Pay': '000004590', 'Ninki...   \n",
       "10366  [{'Kumi': '081115', 'Pay': '000232970', 'Ninki...   \n",
       "10367  [{'Kumi': '020407', 'Pay': '000002580', 'Ninki...   \n",
       "\n",
       "                                            PaySanrentan  Year MonthDay JyoCD  \\\n",
       "0      [{'Kumi': '091308', 'Pay': '000003840', 'Ninki...  2020     0106    06   \n",
       "1      [{'Kumi': '131506', 'Pay': '000026590', 'Ninki...  2022     0105    07   \n",
       "2      [{'Kumi': '070103', 'Pay': '000280650', 'Ninki...  2020     0105    06   \n",
       "3      [{'Kumi': '121103', 'Pay': '000008340', 'Ninki...  2020     0106    06   \n",
       "4      [{'Kumi': '071609', 'Pay': '000009690', 'Ninki...  2020     0106    06   \n",
       "...                                                  ...   ...      ...   ...   \n",
       "10363  [{'Kumi': '010703', 'Pay': '000094870', 'Ninki...  2022     1228    06   \n",
       "10364  [{'Kumi': '040611', 'Pay': '000138570', 'Ninki...  2022     1228    06   \n",
       "10365  [{'Kumi': '041012', 'Pay': '000027420', 'Ninki...  2022     1228    09   \n",
       "10366  [{'Kumi': '110815', 'Pay': '002466010', 'Ninki...  2022     1228    06   \n",
       "10367  [{'Kumi': '070204', 'Pay': '000010260', 'Ninki...  2022     1228    09   \n",
       "\n",
       "      Kaiji Nichiji RaceNum  \n",
       "0        01      02      03  \n",
       "1        01      01      12  \n",
       "2        01      01      01  \n",
       "3        01      02      04  \n",
       "4        01      02      05  \n",
       "...     ...     ...     ...  \n",
       "10363    05      09      03  \n",
       "10364    05      09      02  \n",
       "10365    06      09      11  \n",
       "10366    05      09      11  \n",
       "10367    06      09      12  \n",
       "\n",
       "[10368 rows x 24 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Payout\n",
    "harai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4cf01565",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted column: KisyuCode\n",
      "Converted column: TozaiCD\n",
      "Converted column: ChokyosiCode\n",
      "Converted column: BanusiCode\n",
      "Converted column: course\n",
      "Converted column: cls\n",
      "Converted column: grade\n",
      "Converted column: BreederCode\n",
      "Converted column: KisyuCode_1\n",
      "Converted column: course_1\n",
      "Converted column: cls_1\n",
      "Converted column: grade_1\n",
      "Converted column: KisyuCode_2\n",
      "Converted column: course_2\n",
      "Converted column: cls_2\n",
      "Converted column: grade_2\n",
      "Converted column: KisyuCode_3\n",
      "Converted column: course_3\n",
      "Converted column: cls_3\n",
      "Converted column: grade_3\n",
      "Converted column: KisyuCode_4\n",
      "Converted column: course_4\n",
      "Converted column: cls_4\n",
      "Converted column: grade_4\n",
      "Converted column: KisyuCode_5\n",
      "Converted column: course_5\n",
      "Converted column: cls_5\n",
      "Converted column: grade_5\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Preprocess data\n",
    "'''\n",
    "\n",
    "# Convert string values to float\n",
    "for col in xall.columns:\n",
    "    if xall[col].dtype == \"object\":\n",
    "        # Convert to numeric where possible\n",
    "        xall[col] = pd.to_numeric(xall[col], errors='coerce')\n",
    "        # Replace NaN (from non-numeric values) with 0\n",
    "        xall[col] = xall[col].fillna(0)\n",
    "        print(f\"Converted column: {col}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b869dd3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Split into Train-Test data\n",
    "'''\n",
    "# Number of days to use of testing\n",
    "TEST_DAYS = 90\n",
    "\n",
    "# Date at which the data splits\n",
    "rd = xall[\"racedate\"].unique()[-TEST_DAYS] \n",
    "\n",
    "# split data\n",
    "xtrain = xall[xall['racedate']<rd].reset_index(drop=True).copy()\n",
    "ytrain = yall[xtrain.index].reset_index(drop=True).copy()\n",
    "xtest = xall[xall['racedate']>=rd].reset_index(drop=True).copy()\n",
    "ytest = yall[xtest.index].reset_index(drop=True).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3c0cfafa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(104436, 224) (104436,) (38887, 224) (38887,)\n"
     ]
    }
   ],
   "source": [
    "print(xtrain.shape, ytrain.shape, xtest.shape, ytest.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d0e898",
   "metadata": {},
   "source": [
    "# Winner prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df53b912",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bd2cdc94",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_prediction_winner = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd29c79",
   "metadata": {},
   "source": [
    "### Light Gradient Boosting Machine (Binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "96ab3929",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binarize outputs (simplify ranking to win / lose)\n",
    "ytrain_lgb = ytrain.apply(lambda x: 1 if x==1 else 0)\n",
    "ytest_lgb = ytest.apply(lambda x: 1 if x==1 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e5a57fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training parameters\n",
    "num_boost_round = 100\n",
    "early_stopping_round = 10\n",
    "lgb_train_parameters = {\n",
    " 'max_depth': 10,\n",
    " 'min_data_in_leaf': 50,\n",
    " 'learning_rate': 0.01,\n",
    " 'seed': 1,\n",
    " 'objective': 'binary',\n",
    " 'metric': 'binary_logloss',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9abe724d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation data (training_data=validation_data）\n",
    "xtrain_val = xtrain.copy()\n",
    "ytrain_val_lgb = ytrain_lgb.copy()\n",
    "xtest_val = xtrain.copy()\n",
    "ytest_val_lgb = ytrain_lgb.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "78c34a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare dataset for LGB model\n",
    "train_data_lgb = lgb.Dataset(xtrain_val, label=ytrain_val_lgb) \n",
    "valid_data_lgb = lgb.Dataset(xtest_val, label=ytest_val_lgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "64194d12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=10) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=1024) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.\n",
      "[LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=10) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=1024) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.\n",
      "[LightGBM] [Info] Number of positive: 7532, number of negative: 96904\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.046413 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 17338\n",
      "[LightGBM] [Info] Number of data points in the train set: 104436, number of used features: 212\n",
      "[LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=10) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=1024) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.072121 -> initscore=-2.554560\n",
      "[LightGBM] [Info] Start training from score -2.554560\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's binary_logloss: 0.210151\n"
     ]
    }
   ],
   "source": [
    "# Train a LGB model on our dataset\n",
    "gbm = lgb.train(lgb_train_parameters, \n",
    "                train_data_lgb,\n",
    "                valid_sets=[valid_data_lgb],\n",
    "                num_boost_round=num_boost_round,\n",
    "                callbacks=[lgb.early_stopping(stopping_rounds=early_stopping_round, \n",
    "                            verbose=1)]\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b80ac4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict\n",
    "ypred = gbm.predict(xtest)\n",
    "model_prediction_winner['LightGBM'] = ypred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e3364bc",
   "metadata": {},
   "source": [
    "### XGBoost (Binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ff91306e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost Official Defaults Baseline\n",
    "xgb_train_param = {\n",
    "    \"n_estimators\": 100,\n",
    "    \"max_depth\": 6,\n",
    "    \"learning_rate\": 0.3,\n",
    "    \"objective\": 'binary:logistic',\n",
    "    \"random_state\": 42  # reproducibility\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "34a174d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/noah/gakusai/Horse-Racing/.venv/lib/python3.12/site-packages/xgboost/core.py:771: FutureWarning: Pass `objective` as keyword args.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "bst = xgb.XGBClassifier(xgb_train_param)\n",
    "# fit model\n",
    "bst.fit(xtrain, ytrain)\n",
    "# make predictions\n",
    "ypred = bst.predict(xtest)\n",
    "model_prediction_winner['XGBoost'] = ypred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b38f4ab",
   "metadata": {},
   "source": [
    "### Catboost (Binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "66a24701",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Baseline Parameters\n",
    "cb_train_param = {\n",
    "    \"iterations\": 1000,         # Standard default\n",
    "    \"learning_rate\": None,      # Automatically scales based on dataset size\n",
    "    \"depth\": 6,                 # The \"Goldilocks\" depth for CatBoost\n",
    "    \"loss_function\": 'Logloss', # Standard for binary\n",
    "    \"bootstrap_type\": 'MVS',    # Standard for CPU training\n",
    "    \"verbose\": 100              # Standard to see if it's actually learning\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2dc5cebf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.074986\n",
      "0:\tlearn: 0.6027906\ttotal: 73.2ms\tremaining: 1m 13s\n",
      "100:\tlearn: 0.2020550\ttotal: 2.29s\tremaining: 20.4s\n",
      "200:\tlearn: 0.1972165\ttotal: 4.35s\tremaining: 17.3s\n",
      "300:\tlearn: 0.1920777\ttotal: 6.53s\tremaining: 15.2s\n",
      "400:\tlearn: 0.1870432\ttotal: 8.76s\tremaining: 13.1s\n",
      "500:\tlearn: 0.1822325\ttotal: 11s\tremaining: 11s\n",
      "600:\tlearn: 0.1779849\ttotal: 13.3s\tremaining: 8.81s\n",
      "700:\tlearn: 0.1734606\ttotal: 15.6s\tremaining: 6.67s\n",
      "800:\tlearn: 0.1695032\ttotal: 17.9s\tremaining: 4.44s\n",
      "900:\tlearn: 0.1656794\ttotal: 20.3s\tremaining: 2.23s\n",
      "999:\tlearn: 0.1617462\ttotal: 22.7s\tremaining: 0us\n"
     ]
    }
   ],
   "source": [
    "# 1. Initialize\n",
    "bst = CatBoostClassifier(**cb_train_param)\n",
    "\n",
    "# 2. Convert ytrain to: 1 if the horse came in 1st, 0 if they came in any other position\n",
    "# We do this inline inside the fit function\n",
    "bst.fit(xtrain, (ytrain == 1).astype(int))\n",
    "\n",
    "# 3. Predict (This will now output 1 for predicted winners, 0 for others)\n",
    "ypred = bst.predict(xtest)\n",
    "model_prediction_winner['CatBoost'] = ypred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0884e5f6",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b4856a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Official Defaults Baseline\n",
    "rf_train_param = {\n",
    "    \"n_estimators\": 100,\n",
    "    \"max_depth\": None,      # Traditional RF baseline allows deep trees\n",
    "    \"random_state\": 42,     # For reproducible results\n",
    "    \"n_jobs\": -1            # Uses all available CPU cores (highly recommended)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3386c7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "bst = RandomForestClassifier(**rf_train_param)\n",
    "bst.fit(xtrain, (ytrain).astype(int))\n",
    "ypred = bst.predict(xtest)\n",
    "model_prediction_winner['RandomForest'] = ypred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "306bb668",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1ce4fecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression Official Defaults Baseline\n",
    "logreg_train_param = {\n",
    "    \"penalty\": 'l2',\n",
    "    \"C\": 1.0,\n",
    "    \"solver\": 'lbfgs',\n",
    "    \"max_iter\": 100,\n",
    "    \"random_state\": 42  # For reproducible results\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1b5bd125",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/noah/gakusai/Horse-Racing/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Fill missing values with 0 (Standard quick fix)\n",
    "xtrain_filled = xtrain.fillna(0)\n",
    "xtest_filled = xtest.fillna(0)\n",
    "\n",
    "# Now use these filled versions to fit\n",
    "bst = LogisticRegression(**logreg_train_param)\n",
    "bst.fit(xtrain_filled, (ytrain == 1).astype(int))\n",
    "\n",
    "ypred = bst.predict(xtest_filled)\n",
    "model_prediction_winner['LogisticRegression'] = ypred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a0a562",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f20092a5",
   "metadata": {},
   "source": [
    "### Tansyo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7705dcee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_mrr(ypred, ytrue):\n",
    "    '''\n",
    "    Args:\n",
    "        ypred (numpy.array): predicted ranks (1 or higher) [n, MAX_HORSE]\n",
    "        ytrue (numpy.array): final confirmed ranks [n, MAX_HORSE]\n",
    "    \n",
    "    Returns:\n",
    "        mrr (int)\n",
    "    '''\n",
    "    res = []\n",
    "    for i in range(ytrue.shape[0]):\n",
    "        # Which rank did we predict for the horse that finished 1st?\n",
    "        # If there is a tie, take the smallest value\n",
    "        indices = np.where(ytrue[i, :] == 1) \n",
    "        if indices[0].size > 0:  # There may be races without a 1st-place horse before the start\n",
    "            res.append(1 / ypred[i, np.min(indices)])\n",
    "    return np.mean(res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "23b92706",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reports(df_res):\n",
    "    \"\"\"\n",
    "    Summary: \n",
    "        Outputs a report of the win predictions.\n",
    "\n",
    "    Args:\n",
    "        df_res (pd.DataFrame): Aggregated results from get_win_results\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "\n",
    "    Note:\n",
    "        Races with refunds are excluded from the aggregation\n",
    "    \"\"\"\n",
    "\n",
    "    # Hit rate (accuracy)\n",
    "    tekichu = df_res.apply(lambda x: sum([y in x[\"true\"] for y in x[\"pred\"]]) >= 1, axis=1).astype(int).values\n",
    "    print(\"Number of races\", df_res.shape[0])\n",
    "    print(\"Number of hits\", np.sum(tekichu))\n",
    "    print(\"Hit rate\", np.mean(tekichu), np.std(tekichu, ddof=1), np.std(tekichu, ddof=1) / np.sqrt(df_res.shape[0]))\n",
    "\n",
    "    # Return rate (profitability)\n",
    "    modoshi = df_res.apply(lambda x: sum([x[\"pay\"][y] if y in x[\"true\"] else 0 for y in x[\"pred\"]]) + x[\"henkan\"]*100, axis=1).values\n",
    "    harai = df_res.apply(lambda x: len(x[\"pred\"]), axis=1).values * 100\n",
    "    print(\"Total payout\", np.sum(modoshi))\n",
    "    print(\"Return rate\", np.mean(modoshi/harai), np.std(modoshi/harai, ddof=1), np.std(modoshi/harai, ddof=1) / np.sqrt(df_res.shape[0]))\n",
    "    print(\"※Mean, standard deviation, standard error\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8b9abd30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_win_results(df_bet, df_kekka):\n",
    "    \"\"\"\n",
    "    Summary:\n",
    "        Takes single-win bets as input, merges them with payout data, and outputs the result.\n",
    "\n",
    "    Args:\n",
    "        df_bet (pd.DataFrame): Data containing raceid and win predictions\n",
    "        df_kekka (pd.DataFrame): Payout data extracted from JRA-VAN\n",
    "\n",
    "    Returns:\n",
    "        df_results (pd.DataFrame): Aggregated data for each race\n",
    "\n",
    "    Note:\n",
    "        Because ties can occur, 'true' is a list and 'pay' is a dict\n",
    "    \"\"\"\n",
    "\n",
    "    # Aggregate by raceid\n",
    "    res = []\n",
    "    for raceid in df_bet[\"raceid\"].tolist():\n",
    "        # Get predictions\n",
    "        pred = df_bet[df_bet[\"raceid\"]==raceid][\"win\"].values[0]  # list of predicted horses\n",
    "        # Check win or loss\n",
    "        try:\n",
    "            tmp = df_kekka[df_kekka.raceid==raceid].iloc[0].to_dict()  # target race\n",
    "        except:\n",
    "            print(\"Payout data for this race does not exist.\", raceid)\n",
    "            continue\n",
    "\n",
    "        # Actual winners (true) and their payouts (pay)\n",
    "        true = [x[\"Umaban\"] for x in tmp[\"PayTansyo\"] if x[\"Umaban\"] != '  ']  # list because ties possible\n",
    "        pay = {x[\"Umaban\"]: int(x[\"Pay\"]) for x in tmp[\"PayTansyo\"] if x[\"Umaban\"] != '  '}\n",
    "        henkan = sum([int(tmp[\"HenkanUma\"][x-1]) for x in pred])  # refunded amounts\n",
    "        pred = [f\"{x:02}\" for x in pred]  # convert to string\n",
    "\n",
    "        res.append({\"pred\": pred, \"true\": true, \"pay\": pay, \"henkan\": henkan, \"raceid\": raceid})     \n",
    "\n",
    "    df_res = pd.DataFrame(res)\n",
    "    get_reports(df_res)\n",
    "\n",
    "    return df_res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5d756e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(xtest, ytest, ypred, harai):\n",
    "    \"\"\"\n",
    "    Evaluate predictions for horse races.\n",
    "\n",
    "    Args:\n",
    "        xtest (pd.DataFrame): Test data containing race and horse info\n",
    "        ytest (np.array): True ranks of horses\n",
    "        ypred (np.array): Predicted scores for horses\n",
    "        harai (pd.DataFrame): Payout data\n",
    "\n",
    "    Returns:\n",
    "        df_bet (pd.DataFrame): Betting predictions per race\n",
    "        df_res (pd.DataFrame): Aggregated results with payouts\n",
    "    \"\"\"\n",
    "\n",
    "    # 'jyuni': store the true ranks in a matrix of shape (num_races × 18)\n",
    "    tmp = xtest.copy()\n",
    "    tmp[\"jyuni\"] = ytest\n",
    "    tmp = tmp.groupby(\"raceid\", as_index=False).apply(lambda x: x[\"jyuni\"].values)\n",
    "    jyuni = np.array([[tmp[i][j] if j < len(tmp[i]) else j+1 for j in range(18)] \n",
    "                      for i in range(tmp.shape[0])])  # padding for missing horses\n",
    "    # print(\"jyuni\\n\", jyuni)\n",
    "\n",
    "    # 'pred': store the predicted ranks in a matrix of shape (num_races × 18) \n",
    "    # sorted by descending score\n",
    "    tmp = xtest.copy()\n",
    "    tmp[\"pred\"] = ypred\n",
    "    tmp = tmp.groupby(\"raceid\", as_index=False).apply(\n",
    "        lambda x: np.argsort(np.argsort(-x[\"pred\"].values)) + 1\n",
    "    )\n",
    "    pred = np.array([[tmp[i][j] if j < len(tmp[i]) else j+1 for j in range(18)] \n",
    "                     for i in range(tmp.shape[0])])  # padding\n",
    "    #print(\"pred\\n\", pred)\n",
    "\n",
    "    # Compute MRR (Mean Reciprocal Rank)\n",
    "    mrr = calc_mrr(pred, jyuni)\n",
    "    print(\"mrr\\n\", mrr)\n",
    "        \n",
    "    # df_bet: extract unique raceid rows\n",
    "    df_bet = xtest[[\"raceid\"]].groupby(\"raceid\", as_index=False).apply(lambda x: x.iloc[0])\n",
    "\n",
    "    # win: buy the horse ranked #1 by predicted score (single win)\n",
    "    kaime = [[np.where(pred[i, :] == 1)[0][0] + 1] for i in range(pred.shape[0])]\n",
    "    df_bet[\"win\"] = kaime\n",
    "\n",
    "    # Align payout data\n",
    "    harai = harai.copy()\n",
    "    harai.columns = [x.replace(\"RaceID\", \"raceid\") for x in harai.columns]\n",
    "    harai.raceid = harai.raceid.astype(int)\n",
    "\n",
    "    # Compute and display results\n",
    "    df_res = get_win_results(df_bet, harai)\n",
    "\n",
    "    return df_bet, df_res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ca5442b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Evaluating LightGBM ----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11403/2116485817.py:19: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  tmp = tmp.groupby(\"raceid\", as_index=False).apply(lambda x: x[\"jyuni\"].values)\n",
      "/tmp/ipykernel_11403/2116485817.py:28: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  tmp = tmp.groupby(\"raceid\", as_index=False).apply(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mrr\n",
      " 0.23596079440398804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11403/2116485817.py:40: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_bet = xtest[[\"raceid\"]].groupby(\"raceid\", as_index=False).apply(lambda x: x.iloc[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of races 2856\n",
      "Number of hits 976\n",
      "Hit rate 0.34173669467787116 0.4743748715278793 0.008876516691665327\n",
      "Total payout 235830\n",
      "Return rate 0.8257352941176471 1.2432512677833703 0.023263754664889724\n",
      "※Mean, standard deviation, standard error\n",
      "---- Evaluating XGBoost ----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11403/2116485817.py:19: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  tmp = tmp.groupby(\"raceid\", as_index=False).apply(lambda x: x[\"jyuni\"].values)\n",
      "/tmp/ipykernel_11403/2116485817.py:28: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  tmp = tmp.groupby(\"raceid\", as_index=False).apply(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mrr\n",
      " 0.23836750996270778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11403/2116485817.py:40: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_bet = xtest[[\"raceid\"]].groupby(\"raceid\", as_index=False).apply(lambda x: x.iloc[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of races 2856\n",
      "Number of hits 17\n",
      "Hit rate 0.005952380952380952 0.07693518441053837 0.0014396134567519108\n",
      "Total payout 61060\n",
      "Return rate 0.21379551820728293 3.3596094998969406 0.06286511278993824\n",
      "※Mean, standard deviation, standard error\n",
      "---- Evaluating CatBoost ----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11403/2116485817.py:19: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  tmp = tmp.groupby(\"raceid\", as_index=False).apply(lambda x: x[\"jyuni\"].values)\n",
      "/tmp/ipykernel_11403/2116485817.py:28: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  tmp = tmp.groupby(\"raceid\", as_index=False).apply(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mrr\n",
      " 0.2662751232731061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11403/2116485817.py:40: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_bet = xtest[[\"raceid\"]].groupby(\"raceid\", as_index=False).apply(lambda x: x.iloc[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of races 2856\n",
      "Number of hits 426\n",
      "Hit rate 0.14915966386554622 0.35630816823461975 0.006667249031392721\n",
      "Total payout 203740\n",
      "Return rate 0.7133753501400559 4.983953552786269 0.09325988697357045\n",
      "※Mean, standard deviation, standard error\n",
      "---- Evaluating RandomForest ----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11403/2116485817.py:19: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  tmp = tmp.groupby(\"raceid\", as_index=False).apply(lambda x: x[\"jyuni\"].values)\n",
      "/tmp/ipykernel_11403/2116485817.py:28: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  tmp = tmp.groupby(\"raceid\", as_index=False).apply(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mrr\n",
      " 0.24190010102685794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11403/2116485817.py:40: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_bet = xtest[[\"raceid\"]].groupby(\"raceid\", as_index=False).apply(lambda x: x.iloc[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of races 2856\n",
      "Number of hits 28\n",
      "Hit rate 0.00980392156862745 0.0985454462284114 0.0018439853180180364\n",
      "Total payout 190020\n",
      "Return rate 0.6653361344537815 8.966093130041159 0.16777380106896903\n",
      "※Mean, standard deviation, standard error\n",
      "---- Evaluating LogisticRegression ----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11403/2116485817.py:19: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  tmp = tmp.groupby(\"raceid\", as_index=False).apply(lambda x: x[\"jyuni\"].values)\n",
      "/tmp/ipykernel_11403/2116485817.py:28: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  tmp = tmp.groupby(\"raceid\", as_index=False).apply(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mrr\n",
      " 0.2693263591562004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11403/2116485817.py:40: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_bet = xtest[[\"raceid\"]].groupby(\"raceid\", as_index=False).apply(lambda x: x.iloc[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of races 2856\n",
      "Number of hits 213\n",
      "Hit rate 0.07457983193277311 0.2627581681329854 0.004916738649734262\n",
      "Total payout 191200\n",
      "Return rate 0.6694677871148459 5.183416828152404 0.09699224970909885\n",
      "※Mean, standard deviation, standard error\n"
     ]
    }
   ],
   "source": [
    "# Evaluate every model\n",
    "results_winner_tansyo = {}\n",
    "\n",
    "for model_name, model_ypred in model_prediction_winner.items():\n",
    "    print(f\"---- Evaluating {model_name} ----\")\n",
    "    df_bet, df_res = evaluate(xtest, yall[xtest.index].reset_index(drop=True).copy(), model_ypred, harai)\n",
    "    results_winner_tansyo[model_name] = {\"df_bet\": df_bet, \"df_res\": df_res}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3452c837",
   "metadata": {},
   "source": [
    "### Fukusyo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e7439de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_mrr_fukusyo(ypred, ytrue):\n",
    "    res = []\n",
    "    nb_races = ytrue.shape[0]\n",
    "\n",
    "    for i in range(nb_races):\n",
    "        chosen = np.argmin(ypred[i, :])   # rank 1\n",
    "        if ytrue[i, chosen] <= 3:\n",
    "            res.append(1.0)\n",
    "        else:\n",
    "            res.append(0.0)\n",
    "\n",
    "    return np.mean(res)\n",
    "\n",
    "def get_reports_fukusyo(df_res):\n",
    "    # Hit rate (accuracy)\n",
    "    tekichu = df_res.apply(lambda x: sum([y in x[\"true\"] for y in x[\"pred\"]]) >= 1, axis=1).astype(int).values\n",
    "    print(\"Number of races\", df_res.shape[0])\n",
    "    print(\"Number of hits\", np.sum(tekichu))\n",
    "    print(\"Hit rate\", np.mean(tekichu), np.std(tekichu, ddof=1), np.std(tekichu, ddof=1) / np.sqrt(df_res.shape[0]))\n",
    "\n",
    "    # Return rate (profitability)\n",
    "    modoshi = df_res.apply(lambda x: sum([x[\"pay\"][y] if y in x[\"true\"] else 0 for y in x[\"pred\"]]) + x[\"henkan\"]*100, axis=1).values\n",
    "    harai = df_res.apply(lambda x: len(x[\"pred\"]), axis=1).values * 100\n",
    "    print(\"Total payout\", np.sum(modoshi))\n",
    "    print(\"Return rate\", np.mean(modoshi/harai), np.std(modoshi/harai, ddof=1), np.std(modoshi/harai, ddof=1) / np.sqrt(df_res.shape[0]))\n",
    "    print(\"※Mean, standard deviation, standard error\")\n",
    "\n",
    "def get_win_results_fukusyo(df_bet, df_kekka):\n",
    "    # Aggregate by raceid\n",
    "    res = []\n",
    "    for raceid in df_bet[\"raceid\"].tolist():\n",
    "        # Get predictions\n",
    "        pred = df_bet[df_bet[\"raceid\"]==raceid][\"top3\"].values[0]  # list of predicted horses\n",
    "        # Check bets\n",
    "        try:\n",
    "            tmp = df_kekka[df_kekka.raceid==raceid].iloc[0].to_dict()  # target race\n",
    "        except:\n",
    "            print(\"Payout data for this race does not exist.\", raceid)\n",
    "            continue\n",
    "\n",
    "        # Actual winners (true) and their payouts (pay)\n",
    "        true = [x[\"Umaban\"] for x in tmp[\"PayFukusyo\"] if x[\"Umaban\"] != '  ']  # list because ties possible\n",
    "        pay = {\n",
    "            x[\"Umaban\"]: int(x[\"Pay\"])\n",
    "            for x in tmp[\"PayFukusyo\"]\n",
    "            if x[\"Umaban\"].strip() != \"\" and x[\"Pay\"].strip() != \"\"\n",
    "        }\n",
    "\n",
    "        henkan = sum(\n",
    "            int(tmp[\"HenkanUma\"][x-1])\n",
    "            for x in pred\n",
    "            if str(tmp[\"HenkanUma\"][x-1]).strip() != \"\"\n",
    "        )\n",
    "\n",
    "        pred = [f\"{x:02}\" for x in pred]  # convert to string\n",
    "\n",
    "        res.append({\"pred\": pred, \"true\": true, \"pay\": pay, \"henkan\": henkan, \"raceid\": raceid})     \n",
    "\n",
    "    df_res = pd.DataFrame(res)\n",
    "    get_reports_fukusyo(df_res)\n",
    "\n",
    "    return df_res\n",
    "\n",
    "def evaluate_fukusyo(xtest, ytest, ypred, harai):\n",
    "    # 'jyuni': store the true ranks in a matrix of shape (num_races × 18)\n",
    "    tmp = xtest.copy()\n",
    "    tmp[\"jyuni\"] = ytest\n",
    "    tmp = tmp.groupby(\"raceid\", as_index=False).apply(lambda x: x[\"jyuni\"].values)\n",
    "    jyuni = np.array([[tmp[i][j] if j < len(tmp[i]) else j+1 for j in range(18)] \n",
    "                      for i in range(tmp.shape[0])])  # padding for missing horses\n",
    "\n",
    "    # 'pred': store the predicted ranks in a matrix of shape (num_races × 18) \n",
    "    # sorted by descending score\n",
    "    tmp = xtest.copy()\n",
    "    tmp[\"pred\"] = ypred\n",
    "    tmp = tmp.groupby(\"raceid\", as_index=False).apply(\n",
    "        lambda x: np.argsort(np.argsort(-x[\"pred\"].values)) + 1\n",
    "    )\n",
    "    pred = np.array([[tmp[i][j] if j < len(tmp[i]) else j+1 for j in range(18)] \n",
    "                     for i in range(tmp.shape[0])])  # padding\n",
    "    \n",
    "    # Compute MRR (Mean Reciprocal Rank)\n",
    "    mrr = calc_mrr_fukusyo(pred, jyuni)\n",
    "    print(\"mrr\\n\", mrr)\n",
    "        \n",
    "    # df_bet: extract unique raceid rows\n",
    "    df_bet = xtest[[\"raceid\"]].groupby(\"raceid\", as_index=False).apply(lambda x: x.iloc[0])\n",
    "\n",
    "    # win: buy the horse ranked <= 3 by predicted score\n",
    "    kaime = [[np.where(pred[i, :] <= 3)[0][0] + 1] for i in range(pred.shape[0])]\n",
    "    df_bet[\"top3\"] = kaime\n",
    "\n",
    "    # Align payout data\n",
    "    harai = harai.copy()\n",
    "    harai.columns = [x.replace(\"RaceID\", \"raceid\") for x in harai.columns]\n",
    "    harai.raceid = harai.raceid.astype(int)\n",
    "\n",
    "    # Compute and display results\n",
    "    df_res = get_win_results_fukusyo(df_bet, harai)\n",
    "\n",
    "    return df_bet, df_res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1c65e559",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Evaluating LightGBM ----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11403/4068334179.py:68: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  tmp = tmp.groupby(\"raceid\", as_index=False).apply(lambda x: x[\"jyuni\"].values)\n",
      "/tmp/ipykernel_11403/4068334179.py:76: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  tmp = tmp.groupby(\"raceid\", as_index=False).apply(\n",
      "/tmp/ipykernel_11403/4068334179.py:87: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_bet = xtest[[\"raceid\"]].groupby(\"raceid\", as_index=False).apply(lambda x: x.iloc[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mrr\n",
      " 0.21498599439775912\n",
      "Number of races 2856\n",
      "Number of hits 1495\n",
      "Hit rate 0.5234593837535014 0.4995368156839375 0.009347347738378716\n",
      "Total payout 237530\n",
      "Return rate 0.831687675070028 0.8819780081142924 0.01650359869504206\n",
      "※Mean, standard deviation, standard error\n",
      "---- Evaluating XGBoost ----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11403/4068334179.py:68: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  tmp = tmp.groupby(\"raceid\", as_index=False).apply(lambda x: x[\"jyuni\"].values)\n",
      "/tmp/ipykernel_11403/4068334179.py:76: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  tmp = tmp.groupby(\"raceid\", as_index=False).apply(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mrr\n",
      " 0.22303921568627452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11403/4068334179.py:87: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_bet = xtest[[\"raceid\"]].groupby(\"raceid\", as_index=False).apply(lambda x: x.iloc[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of races 2856\n",
      "Number of hits 168\n",
      "Hit rate 0.058823529411764705 0.2353353214154593 0.0044036015271099365\n",
      "Total payout 158420\n",
      "Return rate 0.5546918767507004 3.2053784227798996 0.0599791362920822\n",
      "※Mean, standard deviation, standard error\n",
      "---- Evaluating CatBoost ----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11403/4068334179.py:68: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  tmp = tmp.groupby(\"raceid\", as_index=False).apply(lambda x: x[\"jyuni\"].values)\n",
      "/tmp/ipykernel_11403/4068334179.py:76: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  tmp = tmp.groupby(\"raceid\", as_index=False).apply(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mrr\n",
      " 0.211484593837535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11403/4068334179.py:87: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_bet = xtest[[\"raceid\"]].groupby(\"raceid\", as_index=False).apply(lambda x: x.iloc[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of races 2856\n",
      "Number of hits 612\n",
      "Hit rate 0.21428571428571427 0.4103977579614743 0.007679375041586616\n",
      "Total payout 182030\n",
      "Return rate 0.6373599439775911 1.853926934024014 0.03469073587727956\n",
      "※Mean, standard deviation, standard error\n",
      "---- Evaluating RandomForest ----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11403/4068334179.py:68: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  tmp = tmp.groupby(\"raceid\", as_index=False).apply(lambda x: x[\"jyuni\"].values)\n",
      "/tmp/ipykernel_11403/4068334179.py:76: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  tmp = tmp.groupby(\"raceid\", as_index=False).apply(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mrr\n",
      " 0.21953781512605042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11403/4068334179.py:87: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_bet = xtest[[\"raceid\"]].groupby(\"raceid\", as_index=False).apply(lambda x: x.iloc[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of races 2856\n",
      "Number of hits 166\n",
      "Hit rate 0.05812324929971989 0.23401733333219402 0.0043789392949330095\n",
      "Total payout 159090\n",
      "Return rate 0.5570378151260504 3.3229593788136387 0.062179314635201106\n",
      "※Mean, standard deviation, standard error\n",
      "---- Evaluating LogisticRegression ----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11403/4068334179.py:68: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  tmp = tmp.groupby(\"raceid\", as_index=False).apply(lambda x: x[\"jyuni\"].values)\n",
      "/tmp/ipykernel_11403/4068334179.py:76: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  tmp = tmp.groupby(\"raceid\", as_index=False).apply(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mrr\n",
      " 0.22023809523809523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11403/4068334179.py:87: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_bet = xtest[[\"raceid\"]].groupby(\"raceid\", as_index=False).apply(lambda x: x.iloc[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of races 2856\n",
      "Number of hits 612\n",
      "Hit rate 0.21428571428571427 0.4103977579614743 0.007679375041586616\n",
      "Total payout 182030\n",
      "Return rate 0.6373599439775911 1.853926934024014 0.03469073587727956\n",
      "※Mean, standard deviation, standard error\n"
     ]
    }
   ],
   "source": [
    "# Evaluate every model\n",
    "results_winner_fukusyo = {}\n",
    "\n",
    "for model_name, model_ypred in model_prediction_winner.items():\n",
    "    print(f\"---- Evaluating {model_name} ----\")\n",
    "    df_bet, df_res = evaluate_fukusyo(xtest, yall[xtest.index].reset_index(drop=True).copy(), model_ypred, harai)\n",
    "    results_winner_fukusyo[model_name] = {\"df_bet\": df_bet, \"df_res\": df_res}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea3581c",
   "metadata": {},
   "source": [
    "### Umaren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "568ef408",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_mrr_umaren(ypred, ytrue):\n",
    "    res = []\n",
    "    for i in range(ypred.shape[0]):\n",
    "        top2 = np.argsort(ypred[i])[:2]\n",
    "        if np.all(ytrue[i, top2] <= 2):\n",
    "            res.append(1.0)\n",
    "        else:\n",
    "            res.append(0.0)\n",
    "    return np.mean(res)\n",
    "\n",
    "\n",
    "def get_reports_umaren(df_res):\n",
    "    tekichu = df_res[\"hit\"].astype(int).values\n",
    "    print(\"Number of races\", df_res.shape[0])\n",
    "    print(\"Number of hits\", np.sum(tekichu))\n",
    "    print(\n",
    "        \"Hit rate\",\n",
    "        np.mean(tekichu),\n",
    "        np.std(tekichu, ddof=1),\n",
    "        np.std(tekichu, ddof=1) / np.sqrt(df_res.shape[0])\n",
    "    )\n",
    "\n",
    "    modoshi = df_res[\"payout\"].values\n",
    "    harai = np.ones(len(modoshi)) * 100\n",
    "    print(\"Total payout\", np.sum(modoshi))\n",
    "    print(\n",
    "        \"Return rate\",\n",
    "        np.mean(modoshi / harai),\n",
    "        np.std(modoshi / harai, ddof=1),\n",
    "        np.std(modoshi / harai, ddof=1) / np.sqrt(df_res.shape[0])\n",
    "    )\n",
    "    print(\"※Mean, standard deviation, standard error\")\n",
    "\n",
    "\n",
    "def get_win_results_umaren(df_bet, df_kekka):\n",
    "    res = []\n",
    "\n",
    "    for raceid in df_bet[\"raceid\"].tolist():\n",
    "        pred = df_bet[df_bet[\"raceid\"] == raceid][\"top2\"].values[0]\n",
    "\n",
    "        try:\n",
    "            tmp = df_kekka[df_kekka.raceid == raceid].iloc[0].to_dict()\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "        true_pairs = [\n",
    "            frozenset([x[\"Kumi\"][:2], x[\"Kumi\"][2:]])\n",
    "            for x in tmp[\"PayUmaren\"]\n",
    "            if x[\"Kumi\"].strip() != \"\"\n",
    "        ]\n",
    "\n",
    "        pay = {\n",
    "            frozenset([x[\"Kumi\"][:2], x[\"Kumi\"][2:]]): int(x[\"Pay\"])\n",
    "            for x in tmp[\"PayUmaren\"]\n",
    "            if x[\"Kumi\"].strip() != \"\" and x[\"Pay\"].strip() != \"\"\n",
    "        }\n",
    "\n",
    "\n",
    "        henkan = sum(\n",
    "            int(tmp[\"HenkanUma\"][x - 1])\n",
    "            for x in pred\n",
    "            if str(tmp[\"HenkanUma\"][x - 1]).strip() != \"\"\n",
    "        )\n",
    "\n",
    "        pred_pair = frozenset([f\"{pred[0]:02}\", f\"{pred[1]:02}\"])\n",
    "\n",
    "        hit = pred_pair in pay\n",
    "        payout = pay[pred_pair] + henkan * 100 if hit else henkan * 100\n",
    "\n",
    "        res.append({\n",
    "            \"raceid\": raceid,\n",
    "            \"pred\": pred_pair,\n",
    "            \"true\": true_pairs,\n",
    "            \"hit\": hit,\n",
    "            \"payout\": payout\n",
    "        })\n",
    "\n",
    "    df_res = pd.DataFrame(res)\n",
    "    get_reports_umaren(df_res)\n",
    "    return df_res\n",
    "\n",
    "\n",
    "def evaluate_umaren(xtest, ytest, ypred, harai):\n",
    "    tmp = xtest.copy()\n",
    "    tmp[\"jyuni\"] = ytest\n",
    "    tmp = tmp.groupby(\"raceid\", as_index=False).apply(lambda x: x[\"jyuni\"].values)\n",
    "    jyuni = np.array([\n",
    "        [tmp[i][j] if j < len(tmp[i]) else j + 1 for j in range(18)]\n",
    "        for i in range(tmp.shape[0])\n",
    "    ])\n",
    "\n",
    "    tmp = xtest.copy()\n",
    "    tmp[\"pred\"] = ypred\n",
    "    tmp = tmp.groupby(\"raceid\", as_index=False).apply(\n",
    "        lambda x: np.argsort(np.argsort(-x[\"pred\"].values)) + 1\n",
    "    )\n",
    "    pred = np.array([\n",
    "        [tmp[i][j] if j < len(tmp[i]) else j + 1 for j in range(18)]\n",
    "        for i in range(tmp.shape[0])\n",
    "    ])\n",
    "\n",
    "    mrr = calc_mrr_umaren(pred, jyuni)\n",
    "    print(\"mrr\\n\", mrr)\n",
    "\n",
    "    df_bet = xtest[[\"raceid\"]].groupby(\"raceid\", as_index=False).apply(lambda x: x.iloc[0])\n",
    "\n",
    "    kaime = [list(np.argsort(pred[i])[:2] + 1) for i in range(pred.shape[0])]\n",
    "    df_bet[\"top2\"] = kaime\n",
    "\n",
    "    harai = harai.copy()\n",
    "    harai.columns = [c.replace(\"RaceID\", \"raceid\") for c in harai.columns]\n",
    "    harai.raceid = harai.raceid.astype(int)\n",
    "\n",
    "    df_res = get_win_results_umaren(df_bet, harai)\n",
    "    return df_bet, df_res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0576bcb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Evaluating LightGBM ----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11403/1730945782.py:86: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  tmp = tmp.groupby(\"raceid\", as_index=False).apply(lambda x: x[\"jyuni\"].values)\n",
      "/tmp/ipykernel_11403/1730945782.py:94: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  tmp = tmp.groupby(\"raceid\", as_index=False).apply(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mrr\n",
      " 0.01365546218487395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11403/1730945782.py:105: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_bet = xtest[[\"raceid\"]].groupby(\"raceid\", as_index=False).apply(lambda x: x.iloc[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of races 2856\n",
      "Number of hits 428\n",
      "Hit rate 0.14985994397759103 0.35699659006234774 0.006680130801089021\n",
      "Total payout 221890\n",
      "Return rate 0.7769257703081233 2.1537089263632585 0.04030026542569199\n",
      "※Mean, standard deviation, standard error\n",
      "---- Evaluating XGBoost ----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11403/1730945782.py:86: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  tmp = tmp.groupby(\"raceid\", as_index=False).apply(lambda x: x[\"jyuni\"].values)\n",
      "/tmp/ipykernel_11403/1730945782.py:94: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  tmp = tmp.groupby(\"raceid\", as_index=False).apply(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mrr\n",
      " 0.022408963585434174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11403/1730945782.py:105: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_bet = xtest[[\"raceid\"]].groupby(\"raceid\", as_index=False).apply(lambda x: x.iloc[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of races 2856\n",
      "Number of hits 0\n",
      "Hit rate 0.0 0.0 0.0\n",
      "Total payout 0\n",
      "Return rate 0.0 0.0 0.0\n",
      "※Mean, standard deviation, standard error\n",
      "---- Evaluating CatBoost ----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11403/1730945782.py:86: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  tmp = tmp.groupby(\"raceid\", as_index=False).apply(lambda x: x[\"jyuni\"].values)\n",
      "/tmp/ipykernel_11403/1730945782.py:94: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  tmp = tmp.groupby(\"raceid\", as_index=False).apply(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mrr\n",
      " 0.018207282913165267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11403/1730945782.py:105: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_bet = xtest[[\"raceid\"]].groupby(\"raceid\", as_index=False).apply(lambda x: x.iloc[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of races 2856\n",
      "Number of hits 71\n",
      "Hit rate 0.024859943977591035 0.1557254577961202 0.002913939393527186\n",
      "Total payout 145400\n",
      "Return rate 0.5091036414565826 4.665179855501379 0.08729498407789314\n",
      "※Mean, standard deviation, standard error\n",
      "---- Evaluating RandomForest ----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11403/1730945782.py:86: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  tmp = tmp.groupby(\"raceid\", as_index=False).apply(lambda x: x[\"jyuni\"].values)\n",
      "/tmp/ipykernel_11403/1730945782.py:94: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  tmp = tmp.groupby(\"raceid\", as_index=False).apply(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mrr\n",
      " 0.0196078431372549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11403/1730945782.py:105: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_bet = xtest[[\"raceid\"]].groupby(\"raceid\", as_index=False).apply(lambda x: x.iloc[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of races 2856\n",
      "Number of hits 1\n",
      "Hit rate 0.00035014005602240897 0.01871202971412799 0.0003501400560224089\n",
      "Total payout 9300\n",
      "Return rate 0.032563025210084036 1.7402187634139032 0.03256302521008403\n",
      "※Mean, standard deviation, standard error\n",
      "---- Evaluating LogisticRegression ----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11403/1730945782.py:86: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  tmp = tmp.groupby(\"raceid\", as_index=False).apply(lambda x: x[\"jyuni\"].values)\n",
      "/tmp/ipykernel_11403/1730945782.py:94: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  tmp = tmp.groupby(\"raceid\", as_index=False).apply(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mrr\n",
      " 0.01715686274509804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11403/1730945782.py:105: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_bet = xtest[[\"raceid\"]].groupby(\"raceid\", as_index=False).apply(lambda x: x.iloc[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of races 2856\n",
      "Number of hits 51\n",
      "Hit rate 0.017857142857142856 0.13245530682547105 0.0024785076371121547\n",
      "Total payout 154420\n",
      "Return rate 0.5406862745098039 5.630792631456031 0.10536355903389821\n",
      "※Mean, standard deviation, standard error\n"
     ]
    }
   ],
   "source": [
    "# Evaluate every model\n",
    "results_winner_umaren = {}\n",
    "\n",
    "for model_name, model_ypred in model_prediction_winner.items():\n",
    "    print(f\"---- Evaluating {model_name} ----\")\n",
    "    df_bet, df_res = evaluate_umaren(xtest, yall[xtest.index].reset_index(drop=True).copy(), model_ypred, harai)\n",
    "    results_winner_umaren[model_name] = {\"df_bet\": df_bet, \"df_res\": df_res}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca13411",
   "metadata": {},
   "source": [
    "# Prediction - Ranking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f84161",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8f7113",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_prediction_ranking = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f80af7a",
   "metadata": {},
   "source": [
    "### LightGBM (rank:pair-wise)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa5d0429",
   "metadata": {},
   "source": [
    "### XGBoost (rank:pair-wise)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "204805d4",
   "metadata": {},
   "source": [
    "### Catboost (rank:pair-wise)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5bf7ca",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "960994bb",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ecc240",
   "metadata": {},
   "source": [
    "### Tansyo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f7c8d35",
   "metadata": {},
   "source": [
    "### Fukusyo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e24005",
   "metadata": {},
   "source": [
    "### Wakuren"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc504d3",
   "metadata": {},
   "source": [
    "### Umaren"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c78b2b8a",
   "metadata": {},
   "source": [
    "### Wide"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f673e6",
   "metadata": {},
   "source": [
    "# Prediction - Time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee93f82",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f4c993",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_prediction_time = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f77a84af",
   "metadata": {},
   "source": [
    "### LightGBM Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b3a8abb",
   "metadata": {},
   "source": [
    "### XGBoost Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e537e52",
   "metadata": {},
   "source": [
    "### Catboost Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e0b96c",
   "metadata": {},
   "source": [
    "### Neural Network Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2552422d",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e156ba8",
   "metadata": {},
   "source": [
    "### Tansyo "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad798cb",
   "metadata": {},
   "source": [
    "### Fukusyo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a34fbea",
   "metadata": {},
   "source": [
    "### Wakuren"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "516c8eab",
   "metadata": {},
   "source": [
    "### Umaren"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0437c3b0",
   "metadata": {},
   "source": [
    "### Wide"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c53ca4",
   "metadata": {},
   "source": [
    "# Results - Methods comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6019e31",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
